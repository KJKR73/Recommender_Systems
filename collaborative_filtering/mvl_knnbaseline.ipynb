{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0528350cce28c00fec30e67128e8a53286b4dae4021c93d92104387f40bb5cc00",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from tqdm import tqdm\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id  rating  timestamp  age gender occupation zip_code  \\\n",
       "0      196      242       3  881250949   49      M     writer    55105   \n",
       "1      186      302       3  891717742   39      F  executive    00000   \n",
       "\n",
       "   movie_id         movie_title  ... fantasy file_noir horror  musical  \\\n",
       "0       242              Kolya   ...       0         0      0        0   \n",
       "1       302  L.A. Confidential   ...       0         1      0        0   \n",
       "\n",
       "   mystery  romance  sci_fi  thriller  war  western  \n",
       "0        0        0       0         0    0        0  \n",
       "1        1        0       0         1    0        0  \n",
       "\n",
       "[2 rows x 32 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n      <th>movie_id</th>\n      <th>movie_title</th>\n      <th>...</th>\n      <th>fantasy</th>\n      <th>file_noir</th>\n      <th>horror</th>\n      <th>musical</th>\n      <th>mystery</th>\n      <th>romance</th>\n      <th>sci_fi</th>\n      <th>thriller</th>\n      <th>war</th>\n      <th>western</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n      <td>49</td>\n      <td>M</td>\n      <td>writer</td>\n      <td>55105</td>\n      <td>242</td>\n      <td>Kolya</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n      <td>891717742</td>\n      <td>39</td>\n      <td>F</td>\n      <td>executive</td>\n      <td>00000</td>\n      <td>302</td>\n      <td>L.A. Confidential</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "master_df = pd.read_csv(\"movie_lens_master.csv\", low_memory=False)\n",
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "400000it [00:07, 50951.41it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings():\n",
    "    # Fetch the glove embedding dictionary\n",
    "    embedding_dict = {}\n",
    "    with open(\"glove\\glove.6B.50d.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            placeholder = line.split()\n",
    "            word = placeholder[0]\n",
    "            values = np.array(placeholder[1:], dtype=np.float32)\n",
    "            embedding_dict[word] = values\n",
    "    \n",
    "    # Return the embedding dict\n",
    "    return embedding_dict\n",
    "\n",
    "glove_50_embeds = get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_input):\n",
    "    \"\"\"\n",
    "    Text Cleaning Function\n",
    "    \"\"\"\n",
    "    # strip and lowercase\n",
    "    text_input = text_input.strip()\n",
    "    text_input = text_input.lower()\n",
    "    \n",
    "    # split the text\n",
    "    text_input = text_input.split()\n",
    "    \n",
    "    # remove punctuations\n",
    "    punct = string.punctuation\n",
    "    table = str.maketrans(\"\", \"\", punct)\n",
    "    text_input =\" \".join([word.translate(table) for word in text_input])\n",
    "    text_input = text_input.strip()\n",
    "    \n",
    "    # Return the text\n",
    "    return text_input\n",
    "\n",
    "# Append the cleaned title as well\n",
    "master_df[\"cleaned_movie_title\"] = master_df[\"movie_title\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_vec(string_in, spatial_dim=50):\n",
    "    split_data = string_in.split()\n",
    "    matrix = np.zeros(spatial_dim, dtype=np.float32)\n",
    "    for word in split_data:\n",
    "        if word in glove_50_embeds.keys():\n",
    "            matrix += glove_50_embeds[word]\n",
    "        else:\n",
    "            matrix += 0.0\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Return precision and recall at k metrics for each user\n",
    "    \"\"\"\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_rating, pred_rating, _ in predictions:\n",
    "        user_est_true[uid].append((pred_rating, true_rating))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_rating >= threshold) for (_, true_rating) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((pred_rating >= threshold) for (pred_rating, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_rating >= threshold) and (pred_rating >= threshold))\n",
    "                              for (pred_rating, true_rating) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Calculates the IOU over the y_true and y_preds based upon the length\n",
    "    \"\"\"\n",
    "    # Handle the length change\n",
    "    len_min = min(len(y_true), len(y_pred))\n",
    "\n",
    "    # Truncate the lenght\n",
    "    y_true = y_true[:len_min]\n",
    "    y_pred = y_pred[:len_min]\n",
    "      \n",
    "    # Convert to set to do set operations\n",
    "    set_y_true = set(list(y_true))\n",
    "    set_y_pred = set(list(y_pred))\n",
    "    \n",
    "    # Set operation\n",
    "    intersection = set_y_pred.intersection(set_y_true)\n",
    "    union = set_y_pred.union(set_y_true)\n",
    "    \n",
    "    if len(union) == 0:\n",
    "        return 0, len(intersection), len(union)\n",
    "    else:\n",
    "        # return the output\n",
    "        return len(intersection) / len(union), len(intersection), len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SURPRISE_DATASET(data, is_train=True):\n",
    "    \"\"\"\n",
    "    Creates a trainset compatiable with surprise models\n",
    "    \"\"\"\n",
    "    # Create the reader scale \n",
    "    reader = surprise.Reader()\n",
    "\n",
    "    # Load from dataframe\n",
    "    dataset = surprise.Dataset.load_from_df(data[['user_id', 'item_id', 'rating']], reader=reader)\n",
    "\n",
    "    # Convert to train dataset\n",
    "    dataset = dataset.build_full_trainset()\n",
    "    \n",
    "    # Check if test or not\n",
    "    if is_train == False:\n",
    "        # Create the test set and return\n",
    "        dataset = dataset.build_testset()\n",
    "        \n",
    "    # return the dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Collaborative_Recommeder_Engine(object):\n",
    "    def __init__(self, models, train_data, val_data, unique_data):\n",
    "        # Init the instance variables\n",
    "        self.models       = models\n",
    "        self.train_data   = train_data\n",
    "        self.val_data     = val_data\n",
    "        self.unique_data  = unique_data\n",
    "        self.total_rec = None\n",
    "        \n",
    "    def get_recommendation(self, user_id, top_many=20, pp=False):\n",
    "        # Calculate the movies not watched\n",
    "        movies_watched = self.train_data[self.train_data[\"user_id\"] == user_id].item_id.values\n",
    "        movies_not_watched = list(set(self.unique_data.item_id.tolist()) - set(movies_watched.tolist()))\n",
    "        \n",
    "        # True labels\n",
    "        true_lbls = self.val_data[self.val_data[\"user_id\"] == user_id][\"movie_title\"].drop_duplicates().values\n",
    "        self.total_rec = top_many # len(true_lbls)\n",
    "        \n",
    "        # If movies unwatched list is empty \n",
    "        if len(movies_not_watched) == 0:\n",
    "            return \"User has watched all movies, no new movies to recommend (get a life bro!)\"\n",
    "        \n",
    "        # Input to the model\n",
    "        X = zip([(user_id - 1)] * len(movies_not_watched), list(movies_not_watched))\n",
    "        \n",
    "        X = pd.DataFrame({\n",
    "            \"user_id\" : [(user_id - 1)] * len(movies_not_watched),\n",
    "            \"item_id\" : list(movies_not_watched),\n",
    "            \"rating\" : [0] * len(movies_not_watched)\n",
    "        })\n",
    "        \n",
    "        X_dataset = SURPRISE_DATASET(data=X, is_train=False)\n",
    "        \n",
    "        # Predict from the mode the ratings\n",
    "        if len(self.models) == 1:\n",
    "            preds_labels = [i[3] for i in self.models[0].test(X_dataset)]\n",
    "            item_ids = [i[1] for i in self.models[0].test(X_dataset)]\n",
    "        else:\n",
    "            # Perform ensemble to get the ratings\n",
    "            preds_labels = np.zeros((len(movies_not_watched), 1))\n",
    "            for model in self.models:\n",
    "                preds_labels += np.array([i[3] for i in model.test(X_dataset)]).reshape(-1, 1)\n",
    "            preds_labels /= len(self.models)\n",
    "            item_ids = [i[1] for i in self.models[0].test(X_dataset)]\n",
    "        \n",
    "        # Collect the index \n",
    "        placeholder = zip(preds_labels, item_ids)\n",
    "        placeholder = sorted(placeholder, key=lambda x:x[0], reverse=True)\n",
    "        index = [placeholder[i][1] for i in range(0,  self.total_rec)]\n",
    "        \n",
    "        # Collect the movies at those positions \n",
    "        placeholder = self.unique_data.set_index(\"item_id\")\n",
    "        \n",
    "        # After processing\n",
    "        if pp:\n",
    "            final_rec, index = self.post_processing_glove(placeholder=placeholder,\n",
    "                                                          movie_ids=index,\n",
    "                                                          user_id=user_id)\n",
    "        else:\n",
    "            final_rec = placeholder.loc[index].movie_title.values[:self.total_rec]\n",
    "        \n",
    "        # Return the recommendations\n",
    "        return final_rec[:self.total_rec], index, true_lbls[:self.total_rec]\n",
    "    \n",
    "    def post_processing_glove(self, placeholder, movie_ids, user_id):\n",
    "        # Fetch the movie ids and the cleaned movie_names\n",
    "        # Choose the highest cosine similarity movies\n",
    "        dict_final = {}\n",
    "        \n",
    "        # Train and val data\n",
    "        recommend_data = placeholder.loc[movie_ids]\n",
    "        watched_movies = self.train_data[self.train_data[\"user_id\"] == user_id].item_id\n",
    "        \n",
    "        # Make the cosine similarity matrix \n",
    "        matrix_csim = cosine_similarity(X=placeholder.loc[watched_movies].values[:, -50:],\n",
    "                                        Y=placeholder.loc[movie_ids].values[:, -50:])\n",
    "        \n",
    "        # Chose the top few movies\n",
    "        for index, (item_id, csim_curr) in enumerate(zip(watched_movies, matrix_csim)):\n",
    "            # Get the recommendations\n",
    "            zipped_recc = zip(matrix_csim[index], recommend_data[\"movie_title\"], recommend_data[\"movie_id\"])\n",
    "            dict_final[placeholder.loc[item_id][\"movie_title\"]] = sorted(zipped_recc, key = lambda x : x[0], reverse=True)\n",
    "                             \n",
    "        # Argsort and send the top 2 from each case\n",
    "        final_list = []\n",
    "        final_ids = []\n",
    "        for i in range(6):\n",
    "            for value in dict_final.values():\n",
    "                _, movie, ids = value[i]\n",
    "                if movie not in final_list:\n",
    "                    final_list.append(movie)\n",
    "                    final_ids.append(ids)\n",
    "            if len(final_list) > self.total_rec:\n",
    "                break\n",
    "                    \n",
    "        # Return the movie\n",
    "        return final_list[:self.total_rec], final_ids[:self.total_rec]\n",
    "            \n",
    "    \n",
    "    def get_score(self, user_id, y_pred, y_pred_ids, t=3.5):\n",
    "        # For IOU\n",
    "        y_true_ids = list(self.val_data[(self.val_data[\"user_id\"] == user_id) & (self.val_data[\"rating\"] >= t)][\"item_id\"].values)\n",
    "        y_pred_ids = list(y_pred_ids)\n",
    "        \n",
    "        # Calculate the IOU\n",
    "        score_iou, _, _ = IOU(y_true=y_true_ids, y_pred=y_pred_ids)\n",
    "            \n",
    "        # Return the scores\n",
    "        return score_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NaN value count : 0\n"
     ]
    }
   ],
   "source": [
    "# Make the cosine similarity dataframe\n",
    "csim_df = master_df[[\"item_id\", \"movie_title\", \"cleaned_movie_title\", \"movie_id\"]].drop_duplicates()\n",
    "list_csim_data = []\n",
    "for movie in csim_df[\"cleaned_movie_title\"]:\n",
    "    list_csim_data.append(title_to_vec(movie))\n",
    "\n",
    "# Convert to array\n",
    "csim_data = np.asarray(list_csim_data)\n",
    "\n",
    "# Append the similarity vector to the dataframe \n",
    "csim_df = pd.concat((csim_df.reset_index(drop=True), pd.DataFrame(csim_data)), axis=1)\n",
    "print(\"NaN value count : %d\" % csim_df.isna().sum().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_machine(pp=False):\n",
    "    model_list = []\n",
    "    # Perform 5-fold scores\n",
    "    for fold in range(5):\n",
    "        train_df = pd.read_csv(\"mvlens_split/fold_%d_train.csv\" % (fold + 1), low_memory=False)\n",
    "        val_df = pd.read_csv(\"mvlens_split/fold_%d_test.csv\" % (fold + 1), low_memory=False)\n",
    "        \n",
    "        # Create the datasets\n",
    "        train_dataset = SURPRISE_DATASET(data=train_df)\n",
    "        train_dataset_rmse = SURPRISE_DATASET(data=train_df, is_train=False)\n",
    "        val_dataset = SURPRISE_DATASET(data=val_df, is_train=False)\n",
    "        \n",
    "        # Create surprise model and train it \n",
    "        model_knnbaseline = surprise.prediction_algorithms.knns.KNNBaseline(verbose=False)\n",
    "        model_knnbaseline.fit(train_dataset)\n",
    "        model_list.append(model_knnbaseline)\n",
    "        \n",
    "        # Fetch the predictions\n",
    "        preds_curr = model_knnbaseline.test(val_dataset)\n",
    "        preds_train = model_knnbaseline.test(train_dataset_rmse)\n",
    "        \n",
    "        # rmse score\n",
    "        rmse_score_val = surprise.accuracy.rmse(preds_curr, verbose=False)\n",
    "        rmse_score_train = surprise.accuracy.rmse(preds_train, verbose=False)\n",
    "        \n",
    "        # Zip the predictions\n",
    "        pre, rec = precision_recall_at_k(predictions=preds_curr, k=10, threshold=3.5)\n",
    "        mean_pre = sum(p for p in pre.values()) / len(pre)\n",
    "        mean_rec = sum(r for r in rec.values()) / len(rec)\n",
    "        \n",
    "        # Create the Engine to make predictions\n",
    "        all_movies_id = csim_df[\"item_id\"]\n",
    "        all_movies_names = csim_df[\"movie_title\"]\n",
    "        engine = Neural_Collaborative_Recommeder_Engine(models=[model_knnbaseline],\n",
    "                                                        train_data=train_df,\n",
    "                                                        val_data=val_df,\n",
    "                                                        unique_data=csim_df)\n",
    "        \n",
    "        # Collect the scores\n",
    "        scores_iou = []\n",
    "        for user in tqdm(val_df.user_id.drop_duplicates()):\n",
    "            y_preds, y_preds_ids, _ = engine.get_recommendation(user_id=user, top_many=10, pp=pp)\n",
    "            scores = engine.get_score(y_pred=y_preds, user_id=user, y_pred_ids=y_preds_ids)\n",
    "            scores_iou.append(scores)\n",
    "        \n",
    "        # Print the metrics\n",
    "        print(\"Fold-%d RMSE  || Train_RMSE : %.4f | Val_RMSE : %.4f\" % (fold + 1,\n",
    "                                                                       rmse_score_train,\n",
    "                                                                       rmse_score_val))\n",
    "        \n",
    "        print(\"Fold-%d IOU   || Mean : %.4f | Max : %.4f\" % (fold + 1,np.mean(scores_iou),\n",
    "                                                           np.max(scores_iou),))\n",
    "        \n",
    "        print(\"Fold-%d MAP@K || Mean : %.4f\" % (fold + 1, np.mean(mean_pre)))\n",
    "        \n",
    "        print(\"Fold-%d MAR@K || Mean : %.4f\" % (fold + 1, np.mean(mean_rec)))\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [02:15<00:00,  3.39it/s]\n",
      "Fold-1 RMSE  || Train_RMSE : 0.7348 | Val_RMSE : 0.9418\n",
      "Fold-1 IOU   || Mean : 0.0055 | Max : 0.1111\n",
      "Fold-1 MAP@K || Mean : 0.7672\n",
      "Fold-1 MAR@K || Mean : 0.4430\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 653/653 [03:05<00:00,  3.53it/s]\n",
      "Fold-2 RMSE  || Train_RMSE : 0.7344 | Val_RMSE : 0.9346\n",
      "Fold-2 IOU   || Mean : 0.0035 | Max : 0.3333\n",
      "Fold-2 MAP@K || Mean : 0.7352\n",
      "Fold-2 MAR@K || Mean : 0.5055\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 869/869 [04:00<00:00,  3.62it/s]\n",
      "Fold-3 RMSE  || Train_RMSE : 0.7357 | Val_RMSE : 0.9292\n",
      "Fold-3 IOU   || Mean : 0.0033 | Max : 0.3333\n",
      "Fold-3 MAP@K || Mean : 0.7039\n",
      "Fold-3 MAR@K || Mean : 0.5553\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 923/923 [04:50<00:00,  3.18it/s]\n",
      "Fold-4 RMSE  || Train_RMSE : 0.7365 | Val_RMSE : 0.9260\n",
      "Fold-4 IOU   || Mean : 0.0019 | Max : 0.3333\n",
      "Fold-4 MAP@K || Mean : 0.6988\n",
      "Fold-4 MAR@K || Mean : 0.5649\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 927/927 [05:14<00:00,  2.95it/s]Fold-5 RMSE  || Train_RMSE : 0.7376 | Val_RMSE : 0.9299\n",
      "Fold-5 IOU   || Mean : 0.0027 | Max : 0.3333\n",
      "Fold-5 MAP@K || Mean : 0.6836\n",
      "Fold-5 MAR@K || Mean : 0.5640\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = model_machine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [02:41<00:00,  2.84it/s]\n",
      "Fold-1 RMSE  || Train_RMSE : 0.7348 | Val_RMSE : 0.9418\n",
      "Fold-1 IOU   || Mean : 0.0055 | Max : 0.2500\n",
      "Fold-1 MAP@K || Mean : 0.7672\n",
      "Fold-1 MAR@K || Mean : 0.4430\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 653/653 [04:24<00:00,  2.47it/s]\n",
      "Fold-2 RMSE  || Train_RMSE : 0.7344 | Val_RMSE : 0.9346\n",
      "Fold-2 IOU   || Mean : 0.0022 | Max : 0.1765\n",
      "Fold-2 MAP@K || Mean : 0.7352\n",
      "Fold-2 MAR@K || Mean : 0.5055\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 869/869 [04:46<00:00,  3.03it/s]\n",
      "Fold-3 RMSE  || Train_RMSE : 0.7357 | Val_RMSE : 0.9292\n",
      "Fold-3 IOU   || Mean : 0.0029 | Max : 0.2000\n",
      "Fold-3 MAP@K || Mean : 0.7039\n",
      "Fold-3 MAR@K || Mean : 0.5553\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 923/923 [05:03<00:00,  3.04it/s]\n",
      "Fold-4 RMSE  || Train_RMSE : 0.7365 | Val_RMSE : 0.9260\n",
      "Fold-4 IOU   || Mean : 0.0015 | Max : 0.1250\n",
      "Fold-4 MAP@K || Mean : 0.6988\n",
      "Fold-4 MAR@K || Mean : 0.5649\n",
      "\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 927/927 [05:01<00:00,  3.07it/s]Fold-5 RMSE  || Train_RMSE : 0.7376 | Val_RMSE : 0.9299\n",
      "Fold-5 IOU   || Mean : 0.0022 | Max : 0.2500\n",
      "Fold-5 MAP@K || Mean : 0.6836\n",
      "Fold-5 MAR@K || Mean : 0.5640\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = model_machine(pp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_true_rec(model_list, user_id, num_folds_to_use, train_data, val_data, top_many=10):\n",
    "    print(\"User_id : %d\" % user_id)\n",
    "        \n",
    "    # Make the recommendation engine\n",
    "    all_movies_id = csim_df[\"item_id\"]\n",
    "    all_movies_names = csim_df[\"movie_title\"]\n",
    "    \n",
    "    # Engine\n",
    "    engine = Neural_Collaborative_Recommeder_Engine(models=model_list,\n",
    "                                                    train_data=train_data,\n",
    "                                                    val_data=val_data,\n",
    "                                                    unique_data=csim_df)\n",
    "    \n",
    "    y_preds, _, true_lbls = engine.get_recommendation(user_id=user_id,\n",
    "                                                      top_many=10,\n",
    "                                                      pp=True)\n",
    "    y_preds_pp, _, _ = engine.get_recommendation(user_id=user_id,\n",
    "                                                 top_many=10,\n",
    "                                                 pp=False)\n",
    "    \n",
    "    data_frame = pd.DataFrame({\n",
    "        \"true\" : true_lbls,\n",
    "        \"recd_normal\" : y_preds,\n",
    "        \"recd_post_process\" : y_preds_pp,\n",
    "    })\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "User_id : 239\n"
     ]
    }
   ],
   "source": [
    "# Declerations \n",
    "num_users = len(np.unique(master_df[\"user_id\"]))\n",
    "num_items = len(np.unique(master_df[\"item_id\"]))\n",
    "train_data = pd.read_csv(\"mvlens_split//fold_1_train.csv\", low_memory=False)\n",
    "val_data = pd.read_csv(\"mvlens_split/fold_1_test.csv\", low_memory=False)\n",
    "user_id = np.random.choice(val_data[\"user_id\"].tolist(), size=1)[0]\n",
    "\n",
    "# Get the dataframe\n",
    "df = compare_true_rec(model_list=model_list, user_id=user_id,\n",
    "                      num_folds_to_use=5,\n",
    "                      train_data=train_data,\n",
    "                      val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          true                     recd_normal  \\\n",
       "0                        Babe          Great Day in Harlem, A    \n",
       "1            Dead Man Walking                 Pather Panchali    \n",
       "2                 Richard III               Some Mother's Son    \n",
       "3                     Ed Wood                        Star Kid    \n",
       "4                Pulp Fiction                    Bitter Sugar    \n",
       "5                   Quiz Show                            Anna    \n",
       "6               Fugitive, The   Saint of Fort Washington, The    \n",
       "7        Hudsucker Proxy, The              Santa with Muscles    \n",
       "8                Blade Runner          Someone Else's America    \n",
       "9  Terminator 2: Judgment Day                   Aiqing wansui    \n",
       "\n",
       "                recd_post_process  \n",
       "0             Santa with Muscles   \n",
       "1  Saint of Fort Washington, The   \n",
       "2              Some Mother's Son   \n",
       "3                Pather Panchali   \n",
       "4                   Bitter Sugar   \n",
       "5                           Anna   \n",
       "6         Great Day in Harlem, A   \n",
       "7                  Aiqing wansui   \n",
       "8         Someone Else's America   \n",
       "9                       Star Kid   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>recd_normal</th>\n      <th>recd_post_process</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Babe</td>\n      <td>Great Day in Harlem, A</td>\n      <td>Santa with Muscles</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dead Man Walking</td>\n      <td>Pather Panchali</td>\n      <td>Saint of Fort Washington, The</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Richard III</td>\n      <td>Some Mother's Son</td>\n      <td>Some Mother's Son</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ed Wood</td>\n      <td>Star Kid</td>\n      <td>Pather Panchali</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pulp Fiction</td>\n      <td>Bitter Sugar</td>\n      <td>Bitter Sugar</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Quiz Show</td>\n      <td>Anna</td>\n      <td>Anna</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Fugitive, The</td>\n      <td>Saint of Fort Washington, The</td>\n      <td>Great Day in Harlem, A</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Hudsucker Proxy, The</td>\n      <td>Santa with Muscles</td>\n      <td>Aiqing wansui</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Blade Runner</td>\n      <td>Someone Else's America</td>\n      <td>Someone Else's America</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Terminator 2: Judgment Day</td>\n      <td>Aiqing wansui</td>\n      <td>Star Kid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df.head(10)"
   ]
  }
 ]
}